---
sidebar_position: 12
title: "Module 4: Vision-Language-Action (VLA)"
---

# Module 4: Vision-Language-Action (VLA)

This module explores the integration of vision, language, and action systems in embodied AI.

## Learning Objectives

By the end of this module, you will understand:
- How to integrate OpenAI Whisper for speech processing
- How to connect LLMs to robot actions
- How to implement ROS 2 actions for complex behaviors
- The principles of multimodal AI systems

## Navigation

- [Integration: Whisper -> LLM -> ROS 2 Actions](./integration.md)

## Next Steps

Complete your learning journey with the Capstone Project.