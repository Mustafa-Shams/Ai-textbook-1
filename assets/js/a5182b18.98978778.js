"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[9509],{3432(e,i,n){n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>l});var t=n(4848),o=n(8453);const s={sidebar_position:13,title:"Integration: Whisper -> LLM -> ROS 2 Actions"},r="Integration: Whisper -> LLM -> ROS 2 Actions",a={id:"module-4/integration",title:"Integration: Whisper -> LLM -> ROS 2 Actions",description:"Voice Processing with OpenAI Whisper",source:"@site/docs/module-4/integration.md",sourceDirName:"module-4",slug:"/module-4/integration",permalink:"/Ai-textbook-1/docs/module-4/integration",draft:!1,unlisted:!1,editUrl:"https://github.com/Mustafa-Shams/ai-textbook/tree/main/website/docs/module-4/integration.md",tags:[],version:"current",sidebarPosition:13,frontMatter:{sidebar_position:13,title:"Integration: Whisper -> LLM -> ROS 2 Actions"},sidebar:"tutorialSidebar",previous:{title:"Module 4: Vision-Language-Action (VLA)",permalink:"/Ai-textbook-1/docs/module-4/"},next:{title:"Capstone Project: The Autonomous Humanoid",permalink:"/Ai-textbook-1/docs/capstone/"}},c={},l=[{value:"Voice Processing with OpenAI Whisper",id:"voice-processing-with-openai-whisper",level:2},{value:"Connecting to Large Language Models",id:"connecting-to-large-language-models",level:2},{value:"ROS 2 Actions for Execution",id:"ros-2-actions-for-execution",level:2},{value:"Complete VLA Pipeline",id:"complete-vla-pipeline",level:2},{value:"Next Steps",id:"next-steps",level:2}];function p(e){const i={h1:"h1",h2:"h2",p:"p",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.h1,{id:"integration-whisper---llm---ros-2-actions",children:"Integration: Whisper -> LLM -> ROS 2 Actions"}),"\n",(0,t.jsx)(i.h2,{id:"voice-processing-with-openai-whisper",children:"Voice Processing with OpenAI Whisper"}),"\n",(0,t.jsx)(i.p,{children:"Using Whisper for speech-to-text conversion in robotic systems."}),"\n",(0,t.jsx)(i.h2,{id:"connecting-to-large-language-models",children:"Connecting to Large Language Models"}),"\n",(0,t.jsx)(i.p,{children:"Integrating LLMs to process natural language and generate action plans."}),"\n",(0,t.jsx)(i.h2,{id:"ros-2-actions-for-execution",children:"ROS 2 Actions for Execution"}),"\n",(0,t.jsx)(i.p,{children:"Implementing ROS 2 actions to execute complex behaviors based on language commands."}),"\n",(0,t.jsx)(i.h2,{id:"complete-vla-pipeline",children:"Complete VLA Pipeline"}),"\n",(0,t.jsx)(i.p,{children:"Building an end-to-end system that processes voice commands and executes robot actions."}),"\n",(0,t.jsx)(i.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(i.p,{children:"Complete your learning journey with the Capstone Project."})]})}function d(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}}}]);