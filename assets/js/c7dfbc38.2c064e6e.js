"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[3267],{4098(e,i,n){n.r(i),n.d(i,{assets:()=>r,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>l,toc:()=>d});var o=n(4848),t=n(8453);const s={sidebar_position:12,title:"Module 4: Vision-Language-Action (VLA)"},a="Module 4: Vision-Language-Action (VLA)",l={id:"module-4/index",title:"Module 4: Vision-Language-Action (VLA)",description:"This module explores the integration of vision, language, and action systems in embodied AI.",source:"@site/docs/module-4/index.md",sourceDirName:"module-4",slug:"/module-4/",permalink:"/ai-textbook/docs/module-4/",draft:!1,unlisted:!1,editUrl:"https://github.com/Mustafa-Shams/ai-textbook/tree/main/website/docs/module-4/index.md",tags:[],version:"current",sidebarPosition:12,frontMatter:{sidebar_position:12,title:"Module 4: Vision-Language-Action (VLA)"},sidebar:"tutorialSidebar",previous:{title:"Nav2 Stack for Bipedal Movement",permalink:"/ai-textbook/docs/module-3/nav2-movement"},next:{title:"Integration: Whisper -> LLM -> ROS 2 Actions",permalink:"/ai-textbook/docs/module-4/integration"}},r={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Navigation",id:"navigation",level:2},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const i={a:"a",h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(i.h1,{id:"module-4-vision-language-action-vla",children:"Module 4: Vision-Language-Action (VLA)"}),"\n",(0,o.jsx)(i.p,{children:"This module explores the integration of vision, language, and action systems in embodied AI."}),"\n",(0,o.jsx)(i.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(i.p,{children:"By the end of this module, you will understand:"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"How to integrate OpenAI Whisper for speech processing"}),"\n",(0,o.jsx)(i.li,{children:"How to connect LLMs to robot actions"}),"\n",(0,o.jsx)(i.li,{children:"How to implement ROS 2 actions for complex behaviors"}),"\n",(0,o.jsx)(i.li,{children:"The principles of multimodal AI systems"}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"navigation",children:"Navigation"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:(0,o.jsx)(i.a,{href:"/ai-textbook/docs/module-4/integration",children:"Integration: Whisper -> LLM -> ROS 2 Actions"})}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(i.p,{children:"Complete your learning journey with the Capstone Project."})]})}function u(e={}){const{wrapper:i}={...(0,t.R)(),...e.components};return i?(0,o.jsx)(i,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);